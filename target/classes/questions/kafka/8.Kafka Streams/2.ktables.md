## Question 1

```markdown
What is a key characteristic of a KTable compared to a KStream?
```

**Options**

```markdown
- A. It represents a log of immutable events
- B. It stores the latest value for each key
- C. It processes events without storing state
- D. It emits all intermediate updates
```

<details><summary>Response:</summary>

**Answer:** B

**Explanation:**

```markdown
KTable models changelog streams where only the latest key-value pairs matter.

- A. KStream fits this description better.
- B. Correct. KTables keep the latest value per key.
- C. KTables are stateful.
- D. It only emits updates when the value changes.
```

</details>

---

## Question 2

```markdown
Which Kafka topic configuration is best suited for KTables?
```

**Options**

```markdown
- A. cleanup.policy = delete
- B. cleanup.policy = compact
- C. cleanup.policy = compress
- D. cleanup.policy = none
```

<details><summary>Response:</summary>

**Answer:** B

**Explanation:**

```markdown
Compaction retains only the latest value per key.

- A. Deletes old segments, not ideal for KTable.
- B. Correct.
- C. Invalid setting.
- D. Not a valid Kafka setting.
```

</details>

---

## Question 3

```markdown
How does a KTable handle a record with a null value?
```

**Options**

```markdown
- A. It deletes the record
- B. It throws an error
- C. It skips the record
- D. It adds the record as-is
```

<details><summary>Response:</summary>

**Answer:** A

**Explanation:**

```markdown
A null value in a KTable is interpreted as a tombstone.

- A. Correct. Null means "delete this key".
- B. No exception is thrown.
- C. It processes the deletion.
- D. It doesn’t keep nulls.
```

</details>

---

## Question 4

```markdown
Which join operation is possible between two KTables?
```

**Options**

```markdown
- A. Windowed join
- B. Left join only
- C. Inner, left, and outer joins
- D. Only stream-table joins
```

<details><summary>Response:</summary>

**Answer:** C

**Explanation:**

```markdown
KTables support all major join types.

- A. Windowed joins are not used with KTables.
- B. Not limited to just left join.
- C. Correct.
- D. That's for KStream–KTable.
```

</details>

---

## Question 5

```markdown
What happens when a KTable receives multiple updates for the same key?
```

**Options**

```markdown
- A. All values are stored
- B. Only the first value is retained
- C. The latest value replaces the old one
- D. It throws an exception
```

<details><summary>Response:</summary>

**Answer:** C

**Explanation:**

```markdown
KTables retain the latest value per key.

- A. KStream does that.
- B. Not true; always latest.
- C. Correct.
- D. Safe update, no error.
```

</details>

---

## Question 6

```markdown
What is emitted by a KTable during a `mapValues()` transformation?
```

**Options**

```markdown
- A. A new KStream of values
- B. A new KTable with updated values
- C. Nothing, transformation is in-place
- D. Only keys, values are discarded
```

<details><summary>Response:</summary>

**Answer:** B

**Explanation:**

```markdown
A `mapValues()` on KTable transforms the value while keeping the key unchanged.

- A. That happens if you convert to stream.
- B. Correct.
- C. KTable emits updates to downstream operators.
- D. Both key and value are retained.
```

</details>

---

## Question 7

```markdown
What kind of topic does a KTable back its state from?
```

**Options**

```markdown
- A. An intermediate topic
- B. A compacted changelog topic
- C. A deleted snapshot topic
- D. A windowed topic
```

<details><summary>Response:</summary>

**Answer:** B

**Explanation:**

```markdown
KTables are backed by compacted changelog topics.

- A. Not accurate.
- B. Correct.
- C. No such concept.
- D. Windowed topics are used in windowed aggregations.
```

</details>

---

## Question 8

```markdown
How does a KTable behave in a join operation?
```

**Options**

```markdown
- A. It re-emits all previous records
- B. It emits an update only when the value changes
- C. It emits nothing
- D. It aggregates values before joining
```

<details><summary>Response:</summary>

**Answer:** B

**Explanation:**

```markdown
KTable emits a change record (old + new) only when a value for a key changes.

- A. No full replays happen.
- B. Correct.
- C. KTables are reactive to updates.
- D. Aggregation is separate.
```

</details>

---

## Question 9

```markdown
What operation converts a KTable to a KStream?
```

**Options**

```markdown
- A. `mapValues()`
- B. `groupByKey()`
- C. `toStream()`
- D. `to()`
```

<details><summary>Response:</summary>

**Answer:** C

**Explanation:**

```markdown
`toStream()` converts a KTable to a KStream of change records.

- A. Just transforms the value.
- B. Grouping operation.
- C. Correct.
- D. Used to write to topic, not convert format.
```

</details>

---

## Question 10

```markdown
If you want to count the number of events per key and store the result, which Kafka Streams abstraction should you use?
```

**Options**

```markdown
- A. KStream
- B. KTable
- C. GlobalKTable
- D. KafkaConsumer
```

<details><summary>Response:</summary>

**Answer:** B

**Explanation:**

```markdown
KTable is ideal for holding aggregates like counts per key.

- A. KStream is raw event stream.
- B. Correct.
- C. Used for lookups, not aggregation.
- D. Not part of Kafka Streams API.
```

</details>



## Question 11

```markdown
In a Kafka Streams application that enriches user clickstream data by joining it with user profile information, what should be the characteristics of the topic storing user profiles for optimal join operations?

StreamsBuilder builder = new StreamsBuilder();
KStream<String, String> clicks = builder.stream("clickstream-topic");
KTable<String, String> profiles = builder.table("user-profiles-topic");
KStream<String, String> enrichedClicks = clicks.join(profiles,
    (click, profile) -> click + " enriched with " + profile);
enrichedClicks.to("enriched-clickstream-topic");
builder.build();
```

**Options**

```markdown
- A. compression.type = snappy
- B. cleanup.policy = delete
- C. cleanup.policy = compact
```

<details><summary>Response:</summary>

**Answer:** C

**Explanation:**

```markdown
Since the topic is used as a KTable, it represents the latest state of each key. Compaction keeps only the latest update per key.

- A. Compression helps with space but isn’t essential for join logic.
- B. Delete policy risks losing historical state.
- C. Correct. Compaction retains latest profile state per user.
```

</details>

---

## Question 12

```markdown
You have an e-commerce application that maintains user information. Which of the following data is best suited to be modeled as a KTable in Kafka Streams?
```

**Options**

```markdown
- A. User clickstream data
- B. User order history
- C. User profile information
- D. User session data
```

<details><summary>Response:</summary>

**Answer:** C

**Explanation:**

```markdown
User profile information is typically updated infrequently and represents the current state for each user. A KTable is ideal for representing such updatable, key-based state.

- A. Clickstream data is better as a KStream due to its real-time, event-based nature.
- B. Order history is event-driven and fits a KStream model better.
- C. Correct. Profile info changes over time and can be modeled as the latest state.
- D. Session data can be modeled using windowed KTables or streams depending on requirements.
```

</details>

---

## Question 13

```markdown
We have a store selling shoes. What dataset is a great candidate to be modeled as a KTable in Kafka Streams?
```

**Options**

```markdown
- A. Money made until now
- B. Items returned
- C. Transaction streams
- D. Inventory content right now
```

<details><summary>Response:</summary>

**Answer:** D

**Explanation:**

```markdown
A KTable is best suited for modeling data that represents the latest state of a key. Here’s the reasoning:

- A. Money made until now – This is an aggregation and could be modeled as a KTable, but it's less direct than inventory.
- B. Items returned – This is more like an event stream, better for KStream.
- C. Transaction streams – These are events over time, best suited for KStream.
- D. Inventory content right now – This is stateful and updated with time, making it a perfect candidate for KTable.
```

</details>

---

## Question 14

```markdown
What is an adequate topic configuration for the topic `word-count-output` in a word-count Kafka Streams application?
```

**Options**

```markdown
- A. compression.type = lz4
- B. cleanup.policy = delete
- C. cleanup.policy = compact
- D. cleanup.policy = compress
```

<details><summary>Response:</summary>

**Answer:** C

**Explanation:**

```markdown
The word-count application outputs results as a KTable, which is a compacted log. Thus, log compaction is necessary.

- A. compression.type = lz4 – This is about compression, not cleanup policy.
- B. cleanup.policy = delete – Deletes old data, not appropriate for KTable semantics.
- C. cleanup.policy = compact – Correct; compaction ensures only the latest key-value pair is retained.
- D. cleanup.policy = compress – Not a valid Kafka configuration.
```

</details>

---