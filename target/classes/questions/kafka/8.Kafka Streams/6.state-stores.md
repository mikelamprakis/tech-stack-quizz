## Question 1

```markdown
What is the primary use of a state store in Kafka Streams?
```

**Options**

```markdown
- A. To store raw Kafka messages
- B. To keep the latest offsets
- C. To store and query local state
- D. To increase consumer throughput
```

<details><summary>Response:</summary>

**Answer:** C

**Explanation:**

```markdown
State stores in Kafka Streams keep local state used in operations like aggregations, joins, and windowing.

- A. Kafka messages are stored in topics.
- B. Offsets are managed by Kafka, not state stores.
- C. Correct.
- D. Not the purpose of state stores.
```

</details>

---

## Question 2

```markdown
Which API is used to access a state store from outside the stream processor?
```

**Options**

```markdown
- A. GlobalKTable
- B. StoreBuilder
- C. Interactive Queries
- D. StateStoreFactory
```

<details><summary>Response:</summary>

**Answer:** C

**Explanation:**

```markdown
Interactive Queries allow you to access the state store directly from a Kafka Streams app.

- A. GlobalKTable is for read-only table joins.
- B. StoreBuilder is for defining stores.
- C. Correct.
- D. No such built-in component.
```

</details>

---

## Question 3

```markdown
What kind of store is created when you perform an aggregation in Kafka Streams?
```

**Options**

```markdown
- A. KeyValueStore
- B. WindowStore
- C. SessionStore
- D. Depends on the type of aggregation
```

<details><summary>Response:</summary>

**Answer:** D

**Explanation:**

```markdown
The type of store depends on the aggregation:

- A. Used for simple aggregations.
- B. Used for windowed aggregations.
- C. Used for session window aggregations.
- D. Correct.
```

</details>

---

## Question 4

```markdown
Which method is used to register a custom state store?
```

**Options**

```markdown
- A. streams.addStore()
- B. builder.registerStore()
- C. topology.addStateStore()
- D. addCustomStore()
```

<details><summary>Response:</summary>

**Answer:** C

**Explanation:**

```markdown
You can attach custom state stores to a topology using `topology.addStateStore(...)`.

- A. Not a valid API.
- B. Doesn’t exist.
- C. Correct.
- D. Not an official method.
```

</details>

---

## Question 5

```markdown
Which of the following best describes a **persistent** state store?
```

**Options**

```markdown
- A. Stored only in memory
- B. Backed by RocksDB and changelogged
- C. Stored in Kafka topics directly
- D. Used for temporary caching only
```

<details><summary>Response:</summary>

**Answer:** B

**Explanation:**

```markdown
Persistent state stores use RocksDB and are backed by a changelog topic in Kafka.

- A. That’s an in-memory store.
- B. Correct.
- C. The changelog is used for recovery, not direct access.
- D. Persistent stores are not just caches.
```

</details>

---

## Question 6

```markdown
What happens if a stateful operation runs without a changelog topic?
```

**Options**

```markdown
- A. Nothing changes
- B. The state is not recoverable after failure
- C. The output topic becomes corrupted
- D. Kafka Streams shuts down
```

<details><summary>Response:</summary>

**Answer:** B

**Explanation:**

```markdown
Without a changelog, state will be lost on restart or failure.

- A. State loss **is** a change.
- B. Correct.
- C. Output topics are unaffected directly.
- D. Streams will still run but with volatile state.
```

</details>

---

## Question 7

```markdown
Which state store interface is best suited for windowed aggregations?
```

**Options**

```markdown
- A. KeyValueStore
- B. TimestampedKeyValueStore
- C. WindowStore
- D. RocksDBStore
```

<details><summary>Response:</summary>

**Answer:** C

**Explanation:**

```markdown
WindowStore handles storing key-value pairs along with window start/end times.

- A. Not window-aware.
- B. Useful for event time but not window ranges.
- C. Correct.
- D. RocksDB is the backend, not the interface.
```

</details>

---

## Question 8

```markdown
Which method is used to retrieve a state store inside a processor?
```

**Options**

```markdown
- A. context.getStateStore()
- B. processor.retrieveStore()
- C. streams.queryStore()
- D. context.store()
```

<details><summary>Response:</summary>

**Answer:** A

**Explanation:**

```markdown
The `ProcessorContext` provides `getStateStore(...)` to access stores inside custom processors.

- A. Correct.
- B. Not a valid API.
- C. That's for interactive queries.
- D. No such method.
```

</details>

---

## Question 9

```markdown
What is a **changelog topic** in the context of Kafka Streams state stores?
```

**Options**

```markdown
- A. A topic for storing Kafka logs
- B. A topic that mirrors state store updates
- C. A topic that holds compacted output data
- D. A topic for temporary intermediate data
```

<details><summary>Response:</summary>

**Answer:** B

**Explanation:**

```markdown
Every persistent store has a changelog topic that reflects all changes to rebuild state on restart.

- A. Kafka log != changelog topic.
- B. Correct.
- C. Compaction applies, but not all compacted topics are changelogs.
- D. That’s repartition topics.
```

</details>

---

## Question 10

```markdown
Which property enables fault-tolerant state recovery in Kafka Streams?
```

**Options**

```markdown
- A. application.id
- B. commit.interval.ms
- C. changelog.topic.replication.factor
- D. bootstrap.servers
```

<details><summary>Response:</summary>

**Answer:** C

**Explanation:**

```markdown
Replicating changelog topics ensures state can be recovered in case of broker failure.

- A. Defines application identity.
- B. Related to commit frequency.
- C. Correct.
- D. Used for connecting, not recovery.
```

</details>



## Question 11

```markdown
Which configuration ensures optimal state store management in a windowed Kafka Streams aggregation?

StreamsBuilder builder = new StreamsBuilder();
KStream<String, Order> orders = builder.stream("orders-topic",
    Consumed.with(Serdes.String(), new JsonSerde<>(Order.class)));
KTable<Windowed<String>, Long> ordersPerHour = orders
    .groupByKey()
    .windowedBy(TimeWindows.of(Duration.ofHours(1)))
    .count(Materialized.as("orders-per-hour-metrics"));
ordersPerHour.toStream().to("orders-metrics-topic");
builder.build();
```

**Options**

```markdown
- A. state.store.replication.factor = 3
- B. state.store.log.compaction = true
- C. commit.interval.ms = 100
```

<details><summary>Response:</summary>

**Answer:** A

**Explanation:**

```markdown
Replication of the state store ensures high availability and fault tolerance.

- A. Correct. Prevents data loss in failures.
- B. Not valid for state store config.
- C. May help with latency but not with resilience.
```

</details>

---

## Question 12

```markdown
What is the role of RocksDB in Kafka Streams?
```

**Options**

```markdown
- A. It is used for storing output topics.
- B. It is used for storing intermediate processing state.
- C. It is used for storing the Kafka Streams application code.
- D. It is not used in Kafka Streams.
```

<details><summary>Response:</summary>

**Answer:** B

**Explanation:**

```markdown
RocksDB is the default local store for maintaining state between processing steps.

- A. Output is written to Kafka topics.
- B. Correct. Used for state storage (joins, aggregations).
- C. Code isn’t stored in RocksDB.
- D. Incorrect. It’s actively used in Kafka Streams.
```

</details>

## Question 13

```markdown
You are running a Kafka Streams application in a Docker container. The application performs a complex join operation and maintains a large state store. Which of the following would provide the greatest performance improvement when restarting the container?
```

**Options**
```markdown
- A. Increase the heap size of the Docker container
- B. Mount a high-performance SSD for the RocksDB directory
- C. Increase the number of replicas for the input topics
- D. Use a more powerful CPU for the Docker host
```

<details><summary>Response:</summary> 

**Answer:** B

**Explanation:**

```markdown
In a Kafka Streams application that maintains a large state store (e.g., for a complex join operation), the bottleneck during restarts is often the time taken to restore the state store from the changelog topic. By mounting a high-performance SSD for the RocksDB directory used by Kafka Streams, the state restore process can be significantly speeded up.

- A is less effective because the heap is used for processing, but the state store is stored on disk (in RocksDB) and loaded into off-heap memory.
- C does not directly impact the state restore performance because the changelogs are already replicated.
- D can help with processing speed but does not address the state restore bottleneck.
```

</details>

## Question 14

```markdown
What is the purpose of state stores in Kafka Streams?
```

**Options**
```markdown
- A. To persist the intermediate results and enable fault tolerance
- B. To cache the input messages for faster processing
- C. To store the final output of the stream processing application
- D. To maintain the configuration of the Kafka Streams application
```

<details><summary>Response:</summary> 

**Answer:** A

**Explanation:**

```markdown
In Kafka Streams, state stores play a crucial role in persisting the intermediate results and enabling fault tolerance for stateful operations.

When a Kafka Streams application performs stateful operations, such as aggregations or joins, it needs to maintain and update a state based on the processed messages. State stores provide a way to persistently store this state outside of the streaming application's memory.

The purpose of state stores is as follows:

1. Persistence: State stores allow the streaming application to persist the intermediate state to disk. This ensures that the state is not lost if the application fails or needs to be restarted. When the application restarts, it can reload the state from the state stores and resume processing from where it left off.

2. Fault Tolerance: By persisting the state, state stores enable fault tolerance in Kafka Streams applications. If a node in the Kafka Streams cluster fails, another node can take over the processing and recover the state from the state stores. This ensures that the processing can continue without losing the accumulated state.

3. Queryable State: State stores in Kafka Streams also provide the ability to query the current state of the application. This allows other applications or services to retrieve the latest computed state without needing to process the entire stream again. Queryable state is useful for serving real-time results or building interactive applications.

State stores in Kafka Streams are backed by an embedded key-value store, such as RocksDB, which provides efficient storage and retrieval of state data. Kafka Streams takes care of managing the state stores, including their creation, updates, and fault tolerance, based on the defined topology and configuration.

It's important to note that state stores are not used for caching input messages or storing the final output of the stream processing application. They are specifically designed to persist and manage the intermediate state required for stateful operations.
```
</details>

## Question 15

```markdown
You have a Kafka Streams application that processes messages from an input topic with 6 partitions. The application performs a stateful aggregation using a KTable. How many local state stores will be created by default?
```
**Options**

```markdown
- A. 1
- B. 3
- C. 6
- D. 12
```

<details><summary>Response:</summary> 

**Answer:** C

**Explanation:**

```markdown
In a Kafka Streams application, when you perform a stateful operation such as aggregation using a KTable, Kafka Streams creates local state stores to maintain the aggregated state for each partition of the input topic. By default, Kafka Streams creates one local state store per partition.

In this scenario, with an input topic having 6 partitions, the Kafka Streams application will create 6 local state stores by default, one for each partition.

Each local state store is associated with a specific partition and maintains the aggregated state for that partition. When a message is processed from a particular partition, the corresponding local state store is updated accordingly.

The number of local state stores created by Kafka Streams is determined by the number of partitions in the input topic and the parallelism of the Kafka Streams application. By default, Kafka Streams uses a parallelism of 1, which means it creates one stream task per partition. Each stream task is responsible for processing messages from its assigned partition and updating the corresponding local state store.

If you increase the parallelism of the Kafka Streams application, multiple stream tasks can be created to process messages from the same partition. In that case, the local state stores are shared among the tasks processing the same partition to ensure consistency.

It's worth noting that the actual number of local state stores created may be influenced by factors such as state store configuration, stream processing topology, and the specific Kafka Streams version being used.
```

</details>

## Question 16

```markdown
What is the role of the `StateStore` in Kafka Streams?
```

**Options**

```markdown
- A. To store the intermediate results of stream processing operations
- B. To store the configuration properties for Kafka Streams applications
- C. To store the metadata information about the Kafka cluster
- D. To store the consumer offsets for Kafka Streams applications
```

<details><summary>Response:</summary>

**Answer:** A

**Explanation:**

```markdown
Kafka Streams uses `StateStore` to manage the state needed for operations like aggregations and joins.

The store provides fault-tolerant local storage, typically backed by RocksDB, to maintain intermediate results.

- A. Correct. StateStores keep state for operations like count, aggregate, join.
- B. Configs are not stored in StateStore—they're part of app configuration.
- C. Cluster metadata is managed by Kafka brokers, not StateStore.
- D. Kafka Streams handles offsets internally, not via StateStore.
```

</details>

---