## Question 1

```markdown
Consider a Kafka topic with the following configuration:

* `cleanup.policy` = "compact,delete"
* `min.cleanable.dirty.ratio` = 0.5
* `delete.retention.ms` = 86400000 (1 day)
* `segment.ms` = 43200000 (12 hours)

Which of the following statements correctly describes the behavior of log compaction and deletion for this topic?

```

**Options**

```markdown
- A. Log compaction and deletion are mutually exclusive; only one policy can be active at any time.
- B. Log compaction will occur once 50% of the segment data is marked as dirty, and logs older than 1 day will be deleted.
- C. Deleted records are removed immediately from the log; `delete.retention.ms` specifies the retention time for all records.
- D. `segment.ms` dictates the maximum lifespan of any record in the log, after which it is eligible for compaction or deletion.
```

<details><summary>Response:</summary>

**Answer:** B

**Explanation:**

```markdown
Kafka supports both compaction and deletion on a topic when `cleanup.policy = compact,delete`.

- Compaction triggers once 50% of a segment is dirty (`min.cleanable.dirty.ratio = 0.5`).
- `delete.retention.ms` specifies how long tombstones (delete markers) are retained (1 day here).
- `segment.ms` controls segment roll frequency, not record retention duration.

- A. Incorrect — compaction and deletion can co-exist.
- B. Correct — reflects actual behavior.
- C. Incorrect — deleted records (tombstones) are kept for retention time.
- D. Incorrect — segment.ms rolls segments, doesn't control retention directly.
```

</details>

---

## Question 9

```markdown
A Kafka cluster is configured with the following:

`log.retention.hours=48`  
`log.retention.bytes=1073741824`  
`log.segment.bytes=536870912`

Assuming a topic has a constant message production rate, which of the following factors will trigger a log segment to be eligible for deletion?
```

**Options**

```markdown
- A. The log segment is older than 48 hours.
- B. The log segment size exceeds 536870912 bytes (512 MB).
- C. The total size of all log segments for the topic exceeds 1073741824 bytes (1 GB).
- D. All of the above.
```

<details><summary>Response:</summary>

**Answer:** D

**Explanation:**

```markdown
Kafka retention policies combine time and size limits:  
- Segments older than 48 hours are eligible for deletion.  
- Segment size exceeding 512 MB can trigger rolling and deletion.  
- Total log size exceeding 1 GB triggers deletion of oldest segments.  

- A. Correct — time-based retention.
- B. Correct — segment size affects segment rolling.
- C. Correct — total size triggers deletion of old segments.
- D. Correct — all factors apply.
```

</details>

---

## Question 11

```markdown
Assuming a Kafka topic is configured with the following settings:

`log.segment.bytes = 1073741824` (1GB)  
`log.retention.ms = 86400000` (1 day)  
`log.retention.bytes = -1`

Which of the following statements accurately describes the log retention policy for this Kafka topic?
```

**Options**

```markdown
- A. Logs are retained based on size; once the log size exceeds 1GB, older segments are deleted.
- B. Logs are retained for exactly one day, regardless of the size of the log.
- C. Logs are retained until the size of the log exceeds 1GB or for one day, whichever comes first.
- D. Logs are retained indefinitely, as `log.retention.bytes` is set to -1, overriding other retention configurations.
```

<details><summary>Response:</summary>

**Answer:** B

**Explanation:**

```markdown
- `log.retention.ms = 86400000` enables time-based retention (1 day).  
- `log.retention.bytes = -1` disables size-based retention.  
- `log.segment.bytes` controls segment file size, not retention policy.

Thus, logs are retained based on time only (1 day), ignoring size.

- A. Incorrect — size-based retention is disabled.
- B. Correct — logs retained for one day regardless of size.
- C. Incorrect — size limit is ignored.
- D. Incorrect — logs are not retained indefinitely.
```

</details>

---

## Question 15

```markdown
Compaction is enabled for a topic in Kafka by setting log.cleanup.policy=compact. What is true about log compaction?
```

**Options**

```markdown
- A. Each message stored in the topic is compressed
- B. Compaction changes the offset of the message
- C. After Cleanup, only one message per key is retained with the latest value
```

<details><summary>Response:</summary>

**Answer:** C

**Explanation:**

```markdown
Log compaction retains the last known value for each key in a partition.
- A. Incorrect, compaction is not compression.
- B. Incorrect, compaction does not change message offsets.
- C. Correct, only one message per key with latest value is retained after cleanup.
```

</details>

---

## Question 5

```markdown
What happens if you produce to a topic that does not exist, and the broker setting `auto.create.topics.enable` is set to `false`?

```

**Options**

```markdown
- A. The broker will create the topic with default configurations
- B. The broker will reject the produce request and the producer will throw an exception
- C. The producer will automatically create the topic
- D. The producer will wait until the topic is created
```

<details><summary>Response:</summary>

**Answer:** B

**Explanation:**

```markdown
When `auto.create.topics.enable=false`, Kafka disallows topic creation on demand. The broker rejects produce requests for non-existent topics, causing producer exceptions.

- A. False — no topic creation when disabled.
- B. Correct — broker rejects and producer errors out.
- C. False — producer does not create topics.
- D. False — producer will not wait, it fails immediately.
```

</details>

---

## Question 6

```markdown
What is the default value of `auto.create.topics.enable` in Kafka?

```

**Options**

```markdown
- A. `true`
- B. `false`
- C. It is not set by default
- D. It depends on the Kafka version
```

<details><summary>Response:</summary>

**Answer:** A

**Explanation:**

```markdown
By default, Kafka has `auto.create.topics.enable` set to `true`. This means topics are auto-created upon first access unless this is explicitly disabled.

- A. Correct — default is true.
- B. False — not default.
- C. False — there is a default setting.
- D. Not generally true; defaults are stable across versions.
```

</details>

---

## Question 7

```markdown
When a topic is automatically created due to `auto.create.topics.enable` being `true`, what configurations are used for the new topic?

```

**Options**

```markdown
- A. The configurations specified by the producer or consumer
- B. The default configurations set on the broker
- C. A combination of producer/consumer configurations and broker defaults
- D. No configurations are set, the topic is created with empty configuration
```

<details><summary>Response:</summary>

**Answer:** B

**Explanation:**

```markdown
Kafka uses the broker's default topic configurations like `num.partitions` and `default.replication.factor` when auto-creating a topic. Client-side configs are ignored.

- A. False — client configs are ignored for auto-creation.
- B. Correct — broker defaults are applied.
- C. False — no mix of configs.
- D. False — defaults are applied, not empty.
```

</details>

---

## Question 16

```markdown
When auto.create.topics.enable is set to true in Kafka configuration,
what are the circumstances under which a Kafka broker automatically creates a topic? (select three)
```

**Options**

```markdown
- A. Producer send message to the topic
- B. Consumer reads message from the topic
- C. Client request the metadata for the topic.
- D. Client Alters the no of partitions of a topic
```

<details><summary>Response:</summary>

**Answer:** A, B, C

**Explanation:**

```markdown
A Kafka broker automatically creates a topic under the following circumstances:
- When a producer starts writing messages to the topic
- When a consumer starts reading messages from the topic
- When any client requests metadata for the topic

D is incorrect, altering partitions does not trigger auto-creation.
```

</details>

---

## Question 20

```markdown
A Kafka broker is configured as follows:

`log.segment.bytes=1073741824`  
`log.segment.ms=86400000`  
`log.retention.bytes=-1`  
`log.retention.ms=604800000`

When will Kafka start a new log segment for a partition, and how long will the old segments be retained?
```

**Options**

```markdown
- A. New segment after 1 GB or 24 hrs; retain for 7 days
- B. New segment after 1 GB or 24 hrs; retain indefinitely
- C. New segment after 1 GB; retain for 7 days or if total exceeds 1 GB
- D. New segment after 24 hrs; retain for 7 days or if total exceeds 1 GB
```

<details><summary>Response:</summary>

**Answer:** A

**Explanation:**

```markdown
Kafka rolls log segments on reaching either size (`1GB`) or time (`24 hours`).  
Retention deletes old segments older than 7 days (`log.retention.ms=604800000`).  
Size-based retention is disabled (`log.retention.bytes=-1`).

- A. Correct — segment rolling and retention times match this option.
- B. Incorrect — retention is time-based, not indefinite.
- C. Incorrect — size retention disabled.
- D. Incorrect — segments roll on size or time, not time alone.
```

</details>

---


## Question 2

```markdown
Kafka is configured with following parameters - log.retention.hours = 168 log.retention.minutes = 168 log.retention.ms = 168  
How long will the messages be retained for?
```

**Options**

```markdown
- A. 168ms
- B. 168 mins
- C. 168 hours
```

<details><summary>Response:</summary>

**Answer:** C

**Explanation:**

```markdown
If more than one similar config is specified, the smaller unit size will take precedence.  
Here all three are set to 168, but Kafka will use the largest unit value that makes sense for retention, which is hours in this case.

- A. Incorrect — milliseconds is the smallest unit but 168 ms is very short retention.
- B. Incorrect — minutes would be shorter retention.
- C. Correct — messages will be retained for 168 hours.
```

</details>

---

## Question 4

```markdown
How often is log compaction evaluated?
```

**Options**

```markdown
- A. Every time a message is sent to Kafka
- B. Every time a new partition is created
- C. Every time a segment is closed
```

<details><summary>Response:</summary>

**Answer:** C

**Explanation:**

```markdown
Log compaction is evaluated every time a segment is closed. It will be triggered if enough data is "dirty" based on the dirty ratio configuration.

- A. Incorrect — compaction is not evaluated on every message.
- B. Incorrect — partition creation does not trigger compaction.
- C. Correct — compaction is evaluated on segment close.
```

</details>

---



## Question 3

```markdown
Once sent to a topic, a message can be modified
```

**Options**

```markdown
- A. Yes
- B. No
```

<details><summary>Response:</summary>

**Answer:** B

**Explanation:**

```markdown
Kafka logs are append-only and the data is immutable. Once a message is written to a topic partition, it cannot be modified.

- A. Incorrect — messages are immutable.
- B. Correct — messages cannot be modified.
```

</details>

---

## Question 14

```markdown
Your topic is log compacted and you are sending a message with the key K and value null. What will happen?
```

**Options**

```markdown
- A. The message will be ignored by the kafka broker.
- B. The producer will throw run time Exception.
- C. The broker will delete all the messages of the Key K on cleanup.
```

<details><summary>Response:</summary>

**Answer:** C

**Explanation:**

```markdown
Sending a message with a null value is called a tombstone in Kafka and signals log compaction to remove all messages with the key K during cleanup.
- A. Incorrect, message is not ignored.
- B. Incorrect, no exception thrown.
- C. Correct, triggers deletion of messages with that key on compaction.
```

</details>

---


## Question 2

```markdown
How does Kafka implement log segment purging?
```

**Options**
```markdown
- A. Using a centralized management system that controls log retention.
- B. Automatically deleting segments older than a specified age without any checks.
- C. Through a background thread that checks and enforces retention policies.
- D. By manually deleting old segments via administrator intervention.
```

<details><summary>Response:</summary>

**Answer:** C

**Explanation:**

```markdown
Kafka uses background threads for retention enforcement.

- A. Incorrect: No centralized system is used.
- B. Incorrect: Checks are performed before deletion.
- C. Correct: Background threads handle retention.
- D. Incorrect: Manual deletion isn't the standard method.
```

</details>

---

## Question 3

```markdown
What are the default settings for Kafka's log cleanup policies? (Select all that apply)
```

**Options**
```markdown
- A. log.cleanup.policy=compact deletes records only after the active log segment is committed.
- B. Data is deleted after a week or when the log reaches a specified maximum size.
- C. log.cleanup.policy=delete is the default setting for user topics.
- D. log.cleanup.policy=compact is used by default for all Kafka topics.
```

<details><summary>Response:</summary>

**Answers:** B, C

**Explanation:**

```markdown
Default cleanup policies:
- B. Correct: Default retention is 1 week/size-based.
- C. Correct: User topics default to 'delete'.
- A. Incorrect: Compact applies only to system topics.
- D. Incorrect: Compact is not universal.
```

</details>

---

## Question 4

```markdown
A company uses Kafka for state restoration and needs to ensure it retains at least the last known value for each key. What feature should they use?
```

**Options**
```markdown
- A. Log retention by time
- B. Log compaction
- C. MirrorMaker for cross-cluster replication
- D. Transactional logging
```

<details><summary>Response:</summary>

**Answer:** B

**Explanation:**

```markdown
Log compaction preserves last key values.

- A. Incorrect: Time-based retention doesn't guarantee key preservation.
- B. Correct: Compaction keeps latest key-value pairs.
- C/D. Incorrect: Unrelated to key-value retention.
```

</details>

---

## Question 5

```markdown
You are responsible for managing a Kafka cluster and need to ensure that log data does not consume excessive storage space. How does Kafka manage log retention, and what configuration options do you have to control it?
```

**Options**
```markdown
- A. Kafka uses external scripts to manage log retention based on user-defined conditions.
- B. Kafka's log retention is managed through policies based on time (log.retention.hours), size (log.retention.bytes), or both.
- C. Kafka automatically deletes old data without any configurable policies.
- D. Kafka's log retention is managed through policies based on message priority.
```

<details><summary>Response:</summary>

**Answer:** B

**Explanation:**

```markdown
Retention is configurable via time/size parameters.

- A. Incorrect: No external scripts are used.
- B. Correct: Time/size parameters control retention.
- C. Incorrect: Policies are configurable.
- D. Incorrect: Priority isn't a retention factor.
```

</details>

---

## Question 6

```markdown
What feature allows Kafka to retain large amounts of data for a configurable period?
```

**Options**
```markdown
- A. Disk-based retention
- B. In-memory storage
- C. Log compaction
- D. Transactional support
```

<details><summary>Response:</summary>

**Answer:** A

**Explanation:**

```markdown
Disk storage enables flexible retention.

- A. Correct: Disk storage supports large data volumes.
- B. Incorrect: Memory is limited.
- C/D. Incorrect: Unrelated to data volume retention.
```

</details>

---

## Question 7

```markdown
How does the log.segment.bytes setting affect Kafka's storage layer?
```

**Options**
```markdown
- A. It limits the total storage used by all logs on a broker.
- B. It deletes old segments to free up space.
- C. It compresses log segments to save disk space.
- D. It determines the maximum size of a log segment before rolling over to a new one.
```

<details><summary>Response:</summary>

**Answer:** D

**Explanation:**

```markdown
Controls segment file sizing.

- A. Incorrect: Doesn't limit total storage.
- B. Incorrect: Deletion is handled separately.
- C. Incorrect: Compression is a separate setting.
- D. Correct: Defines segment file size threshold.
```

</details>

---

## Question 9

```markdown
A stateful application needs to restore its state using Kafka and requires access to at least the last known value for each key. Which Kafka feature should be utilized?
```

**Options**
```markdown
- A. Log compaction.
- B. Transactional logs.
- C. Retention policies.
- D. Log cleaning.
```

<details><summary>Response:</summary>

**Answer:** A

**Explanation:**

```markdown
Log compaction preserves latest values.

- A. Correct: Maintains last value per key.
- B/C/D. Incorrect: Don't guarantee key-value retention.
```

</details>

---

## Question 10

```markdown
How does Kafka manage log files to ensure efficient storage and data availability?
```

**Options**
```markdown
- A. By rotating log files based on time or size
- B. By deleting old log files based on size
- C. By storing log files in a distributed manner
- D. By compressing all log files
```

<details><summary>Response:</summary>

**Answer:** A

**Explanation:**

```markdown
Log rotation optimizes storage.

- A. Correct: Time/size-based rotation.
- B. Incorrect: Deletion follows retention policies.
- C. Incorrect: Distribution is separate from rotation.
- D. Incorrect: Compression is optional.
```

</details>

---
