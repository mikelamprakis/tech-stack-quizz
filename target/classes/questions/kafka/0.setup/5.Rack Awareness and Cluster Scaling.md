## Question 1

```markdown
What is the primary purpose of the `broker.rack` configuration in Kafka?
```

**Options**

```markdown
- A. To assign unique broker IDs
- B. To enable Kafka monitoring tools
- C. To guide replica placement across failure domains
- D. To configure controller election preference
```

<details><summary>Response:</summary>

**Answer:** C

**Explanation:**

```markdown
- A. Incorrect: `broker.id` is used for unique broker IDs.
- B. Incorrect: Monitoring is unrelated to `broker.rack`.
- C. Correct: `broker.rack` helps Kafka spread replicas across different racks or AZs to improve fault tolerance.
- D. Incorrect: Controller election is not affected by this setting.
```

</details>

---

## Question 2

```markdown
What could happen if Kafka is deployed without proper rack awareness?
```

**Options**

```markdown
- A. Producers may overload one partition
- B. All replicas of a partition might reside on the same rack
- C. Consumers will experience rebalancing more often
- D. Brokers will refuse to start
```

<details><summary>Response:</summary>

**Answer:** B

**Explanation:**

```markdown
- A. Incorrect: This relates to partitioning strategy, not rack awareness.
- B. Correct: Without rack awareness, Kafka may co-locate all replicas on the same rack, risking total data loss during a rack failure.
- C. Incorrect: Consumer rebalancing is not driven by rack awareness.
- D. Incorrect: Brokers start normally regardless of this config.
```

</details>

---

## Question 3

```markdown
Why is having too many partitions per broker a scalability concern in Kafka?
```

**Options**

```markdown
- A. Kafka limits topics to 10 partitions each
- B. High partition counts increase controller and heap load
- C. Consumers cannot handle large partition counts
- D. Brokers will refuse replication duties
```

<details><summary>Response:</summary>

**Answer:** B

**Explanation:**

```markdown
- A. Incorrect: Kafka supports thousands of partitions per topic.
- B. Correct: Each partition adds metadata, open file descriptors, and increases GC pressure on the broker.
- C. Incorrect: Consumers can scale with partitions but are not the limiting factor here.
- D. Incorrect: Brokers handle replication based on config, not partition count alone.
```

</details>

---

## Question 4

```markdown
Which of the following is a recommended default for partitions per broker in production Kafka clusters?
```

**Options**

```markdown
- A. 10–50
- B. 1,000–2,000
- C. 100–300
- D. 5,000–10,000
```

<details><summary>Response:</summary>

**Answer:** C

**Explanation:**

```markdown
- A. Incorrect: Too low for production workloads.
- B. Incorrect: Acceptable for large clusters but not the starting point.
- C. Correct: 100–300 partitions per broker is a healthy default for balanced performance.
- D. Incorrect: Very high and only suitable for advanced users with specific tuning.
```

</details>

---

## Question 5

```markdown
What is the safest way to remove a broker from a Kafka cluster?
```

**Options**

```markdown
- A. Shut it down immediately and delete its logs
- B. Run a rolling restart of all brokers
- C. Use the partition reassignment tool to drain data first
- D. Remove its entry from ZooKeeper
```

<details><summary>Response:</summary>

**Answer:** C

**Explanation:**

```markdown
- A. Incorrect: This risks data loss and under-replicated partitions.
- B. Incorrect: This doesn't remove the broker safely.
- C. Correct: Partitions must be reassigned away from the broker before decommissioning.
- D. Incorrect: Manual removal from ZooKeeper is not a safe process.
```

</details>

---

## Question 6

```markdown
What is a key benefit of using Cruise Control with Kafka at scale?
```

**Options**

```markdown
- A. Manages topic compaction automatically
- B. Handles leader election logic
- C. Automates load balancing and anomaly detection
- D. Encrypts inter-broker traffic
```

<details><summary>Response:</summary>

**Answer:** C

**Explanation:**

```markdown
- A. Incorrect: Topic compaction is handled via configs, not Cruise Control.
- B. Incorrect: Leader election is managed internally by Kafka.
- C. Correct: Cruise Control helps automate partition reassignments and identify overloaded brokers.
- D. Incorrect: Encryption is configured separately.
```

</details>

---

## Question 7

```markdown
Which setting allows Kafka to auto-generate broker IDs instead of assigning them manually?
```

**Options**

```markdown
- A. broker.id.auto=true
- B. broker.discovery.enable=true
- C. broker.id.generation.enable=true
- D. enable.auto.id=true
```

<details><summary>Response:</summary>

**Answer:** C

**Explanation:**

```markdown
- A. Incorrect: Not a valid property.
- B. Incorrect: Not related to broker IDs.
- C. Correct: `broker.id.generation.enable=true` allows Kafka to assign IDs automatically (Kafka 2.4+).
- D. Incorrect: Not a recognized Kafka setting.
```

</details>

---

## Question 8

```markdown
When adding a new broker to a Kafka cluster, what must you ensure before starting the process?
```

**Options**

```markdown
- A. That all topics are compacted
- B. That the broker uses the same JVM version
- C. That the broker has a unique `broker.id`
- D. That the broker listens on port 8080
```

<details><summary>Response:</summary>

**Answer:** C

**Explanation:**

```markdown
- A. Incorrect: Compaction is unrelated to adding brokers.
- B. Incorrect: JVM version compatibility is important but not the most critical step.
- C. Correct: Each broker must have a unique `broker.id` to join the cluster.
- D. Incorrect: Kafka's default port is 9092, not 8080.
```

</details>

---


## Question 9

```markdown
Select all strategies that are essential for effectively scaling Kafka data pipelines:
```

**Options**
```markdown
- A. Increasing the number of partitions to enable better parallelism.
- B. Employing a distributed Kafka Streams approach.
- C. Integrating Kafka with scalable external storage systems.
- D. Utilizing data compaction to reduce the data footprint.
```

<details><summary>Response:</summary>

**Answer:** A, B

**Explanation:**

```markdown
Effective scaling of Kafka data pipelines can be achieved by:

Using Kafka Streams, which allows for distributed stream processing, enhancing the capability to handle large data volumes through parallel processing.

Increasing the number of partitions enhances parallelism, allowing more consumers to process data concurrently, thereby improving throughput and reducing processing time.
```

</details>

---

## Question 10

```markdown
What characteristic makes Kafka highly scalable?
```

**Options**
```markdown
- A. Fixed number of partitions
- B. Single-threaded operations
- C. Distributed architecture
- D. In-memory computing
```

<details><summary>Response:</summary>

**Answer:** C

**Explanation:**

```markdown
Kafka is highly scalable due to its distributed architecture, which allows topics to be partitioned and replicated across multiple brokers.
```

</details>

---
