## Question 1

```markdown
What is the primary purpose of the `tasks.max` configuration in Kafka Connect?
```

**Options**

```markdown
- A. Sets maximum record size
- B. Controls worker heap memory
- C. Defines the number of tasks for parallel execution
- D. Limits number of topic partitions
```

<details><summary>Response:</summary>

**Answer:** C

**Explanation:**

```markdown
- A. Not related to record size
- B. Worker heap is controlled via JVM
- C. ✅ It defines how many tasks can run concurrently for a connector
- D. Topic partitions are independent of this setting
```

</details>

---

## Question 2

```markdown
When configuring a JDBC Source Connector for parallelism, how should `tasks.max` relate to the tables?
```

**Options**

```markdown
- A. It must be greater than the number of tables
- B. It should match the number of Kafka topics
- C. It should be less than or equal to the number of tables
- D. It must be set to 1 always
```

<details><summary>Response:</summary>

**Answer:** C

**Explanation:**

```markdown
- A. Over-provisioning offers no benefit
- B. Topics aren't relevant here
- C. ✅ Each task can read from one or more tables; ≤ # of tables is efficient
- D. Setting it to 1 disables parallelism
```

</details>

---

## Question 3

```markdown
Which configuration controls how many records a sink connector will flush at once?
```

**Options**

```markdown
- A. batch.size
- B. flush.size
- C. tasks.max
- D. buffer.limit
```

<details><summary>Response:</summary>

**Answer:** B

**Explanation:**

```markdown
- A. Used for source batching
- B. ✅ flush.size controls how many records are written to the sink at once
- C. Manages parallelism, not flushing
- D. Not a valid Kafka Connect config
```

</details>

---

## Question 4

```markdown
What’s a recommended tuning value for `flush.size` when dealing with slow sink systems like databases?
```

**Options**

```markdown
- A. Keep it very low (e.g., 10)
- B. Set it to 0 to disable flushing
- C. Match it to the DB's batch insert limit
- D. Always use the Kafka default
```

<details><summary>Response:</summary>

**Answer:** C

**Explanation:**

```markdown
- A. Low values underuse resources
- B. Flush cannot be disabled this way
- C. ✅ Match flush.size to DB batch limit for optimal performance
- D. Defaults are not optimized for every use case
```

</details>

---

## Question 5

```markdown
Which worker-level setting controls how long Connect waits for tasks to shut down cleanly?
```

**Options**

```markdown
- A. offset.flush.timeout.ms
- B. consumer.max.poll.records
- C. task.shutdown.graceful.timeout.ms
- D. connect.shutdown.ms
```

<details><summary>Response:</summary>

**Answer:** C

**Explanation:**

```markdown
- A. Timeout for flushing offsets
- B. Controls consumer poll behavior
- C. ✅ Used for graceful task shutdown
- D. Not a valid Connect config
```

</details>

---

## Question 6

```markdown
What metric would you monitor to assess average Kafka Connect batch size?
```

**Options**

```markdown
- A. offset-lag-max
- B. poll-rate
- C. batch-size-avg
- D. commit-latency
```

<details><summary>Response:</summary>

**Answer:** C

**Explanation:**

```markdown
- A. Used for consumer lag
- B. Reflects source polling frequency
- C. ✅ Tracks average records per batch
- D. Measures offset commit latency, not batching
```

</details>

---

## Question 7

```markdown
How does increasing `batch.size` and `flush.size` affect performance?
```

**Options**

```markdown
- A. Reduces memory usage
- B. Reduces latency but increases memory use
- C. Increases throughput but may increase memory pressure
- D. Decreases disk usage
```

<details><summary>Response:</summary>

**Answer:** C

**Explanation:**

```markdown
- A. Larger batches consume more memory
- B. Larger batches typically increase latency
- C. ✅ Throughput improves, but memory usage also rises
- D. Kafka does not write to disk in this context
```

</details>

---

## Question 8

```markdown
What is a recommended action if your connector is CPU-bound?
```

**Options**

```markdown
- A. Decrease `tasks.max`
- B. Increase `batch.size`
- C. Increase `tasks.max` or use more workers
- D. Tune the sink connector to reduce flushing
```

<details><summary>Response:</summary>

**Answer:** C

**Explanation:**

```markdown
- A. Reduces parallelism and can worsen performance
- B. Helps only in I/O-bound scenarios
- C. ✅ Adding more tasks or scaling out helps distribute CPU load
- D. Not the primary bottleneck in CPU-heavy cases
```

</details>

---

## Question 9

```markdown
In a real-world S3 Sink example, what does increasing `flush.size` accomplish?
```

**Options**

```markdown
- A. Uploads more but smaller files to S3
- B. Reduces the number of PUT operations to S3
- C. Flushes data faster
- D. Makes logs more verbose
```

<details><summary>Response:</summary>

**Answer:** B

**Explanation:**

```markdown
- A. Actually results in fewer but larger files
- B. ✅ Bigger flushes = fewer S3 uploads
- C. Flush rate depends on size or time
- D. Not related to logging
```

</details>

---

## Question 10

```markdown
What’s a suggested method to validate Kafka Connect performance tuning in a safe way?
```

**Options**

```markdown
- A. Change configs directly in production
- B. Restart Kafka brokers
- C. Test changes in a staging environment
- D. Use `kafka-topics.sh` for all tuning
```

<details><summary>Response:</summary>

**Answer:** C

**Explanation:**

```markdown
- A. Risky and not best practice
- B. Unnecessary for connector tuning
- C. ✅ Safe and controlled way to test performance impact
- D. That script manages topics, not performance configs
```

</details>

---

## Question 11

```markdown  
How does Kafka Connect handle the scalability of connectors?  
```  

**Options**
```markdown  
- A. By automatically creating multiple instances of a connector based on the load  
- B. By allowing manual configuration of the number of tasks for each connector  
- C. By dynamically adjusting the number of tasks based on the connector's performance  
- D. By requiring a separate Kafka Connect cluster for each connector  
```  

<details><summary>Response:</summary>  

**Answer:** B

**Explanation:**

```markdown  
Scalability is achieved through configurable tasks.  

- A. Scaling is not automatic  
- B. Correct. `tasks.max` controls parallelism  
- C. Task count is static once configured  
- D. Multiple connectors can share a cluster  
```  

</details>  

---  

## Question 12

```markdown  
How can you increase the parallelism of a JDBC source connector to improve the performance of copying data from a database to Kafka?  
```  

**Options**
```markdown  
- A. Increase the `max.tasks` configuration of the connector  
- B. Increase the number of partitions in the target Kafka topic  
- C. Increase the `tasks.max` configuration of the Kafka Connect workers  
- D. Use multiple instances of the JDBC connector, each copying a different subset of tables  
```  

<details><summary>Response:</summary>  

**Answer:** A and D

**Explanation:**

```markdown  
Both approaches can increase parallelism effectively.  

- A. Correct. More tasks per connector instance  
- B. Helps consumers but not source parallelism  
- C. Increases cluster capacity but not connector parallelism  
- D. Correct. Horizontal scaling with multiple connectors  
```  

</details>  


---

## Question 13

```markdown  
An e-commerce company uses Kafka to process customer orders. During sales events, the order volume spikes significantly. Which approach ensures the system scales efficiently to handle these spikes in order volume?  
```  

**Options**
```markdown  
- A. Automatically adjust the number of topics to spread the increased order messages across more Kafka topics during sales events  
- B. Use Kafka Connect with scalable Source Connectors to adjust the throughput based on order volume  
- C. Scale out the Kafka broker cluster by adding more brokers during high-volume periods and scale in when the volume decreases  
- D. Configure the Kafka producer to dynamically adjust batch size and linger time based on the current throughput of order messages  
```  

<details><summary>Response:</summary>  

**Answer:** C

**Explanation:**

```markdown  
Scaling the broker cluster provides horizontal scaling for the entire Kafka system during peak loads.  

- A. Adding topics doesn't inherently increase processing capacity  
- B. Source Connectors manage data ingestion, not system capacity  
- C. Correct. Adding brokers increases overall cluster capacity  
- D. Producer tuning helps but doesn't address system-wide scaling  
```  

</details>  

---  

## Question 14

```markdown  
A streaming media company uses Kafka to ingest viewer watch history for real-time recommendation updates. Viewer engagement varies greatly, with peak times during new content releases. To handle variable ingestion rates, which configuration should be optimized?  
```  

**Options**
```markdown  
- A. Adjust the replication factor of the watch history topic in real-time to handle the increased data volume  
- B. Increase and decrease the number of Kafka Connect Sink Connector tasks to efficiently write watch history data into Kafka  
- C. Scale the number of Kafka Streams applications processing the watch history data according to the ingestion rate  
- D. Dynamically modify the number of partitions in the watch history topic to manage the load during peak engagement times  
```  

<details><summary>Response:</summary>  

**Answer:** C

**Explanation:**

```markdown  
Scaling processing capacity matches the variable workload most effectively.  

- A. Replication factor affects durability, not processing capacity  
- B. Sink Connectors export data from Kafka, not ingest  
- C. Correct. Kafka Streams can scale elastically with demand  
- D. Changing partitions dynamically is operationally complex  
```  

</details>  

---  

## Question 15

```markdown  
A digital marketing platform analyzes user activities to send personalized marketing emails. The platform uses Kafka to stream activity data, with fluctuations in data volume throughout the day. To ensure optimal performance during peak data inflow, what strategy should be employed?  
```  

**Options**
```markdown  
- A. Dynamically adjust the number of partitions in the user activities topic based on incoming data volume.  
- B. Scale the Kafka Streams application instances up or down in response to the processing load.  
- C. Increase or decrease the number of Kafka Connect Source Connector tasks to match the rate of incoming user activity data.  
- D. Modify the replication factor of the user activities topic during high load periods to improve data durability and availability.  
```  

<details><summary>Response:</summary>  

**Answer:** B

**Explanation:**

```markdown  
Scaling processing capacity matches the variable workload most effectively.  

- A. Partition changes require careful planning and aren't dynamic.  
- B. Correct. Kafka Streams supports elastic scaling.  
- C. Connector tasks manage ingestion, not processing load.  
- D. Replication factor doesn't address processing capacity.  
```  

</details>  
