## Question 1

```markdown
What is the key conceptual difference between a ksqlDB STREAM and TABLE?
```

**Options**

```markdown
- A. Streams require a key while tables do not.
- B. Tables are append-only logs, while streams reflect the latest value per key.
- C. Streams are event logs; tables are materialized state per key.
- D. Streams are static, while tables are dynamic.
```

<details><summary>Response:</summary>

**Answer:** C

**Explanation:**

```markdown
- A. Incorrect – tables require keys.
- B. Reversed roles.
- C. ✅ Correct – streams represent event logs; tables represent evolving state.
- D. Misleading – both update dynamically.
```

</details>

---

## Question 2

```markdown
In ksqlDB, which of the following is mandatory when defining a TABLE?
```

**Options**

```markdown
- A. KAFKA_TOPIC
- B. PRIMARY KEY
- C. PARTITIONS
- D. VALUE_FORMAT
```

<details><summary>Response:</summary>

**Answer:** B

**Explanation:**

```markdown
- A. Needed but not specific to tables.
- B. ✅ Correct – tables require a PRIMARY KEY.
- C. Set at Kafka topic level, not CREATE TABLE.
- D. Important, but not unique to tables.
```

</details>

---

## Question 3

```markdown
Why would you use `EMIT CHANGES` in a SELECT query?
```

**Options**

```markdown
- A. To return only the final aggregated result.
- B. To fetch historical data from a topic.
- C. To enable the query to continuously output results as events arrive.
- D. To store query results in a new Kafka topic.
```

<details><summary>Response:</summary>

**Answer:** C

**Explanation:**

```markdown
- A. EMIT CHANGES doesn't finalize output.
- B. Historical replay isn't the goal here.
- C. ✅ Correct – turns query into continuous/push query.
- D. Use `INSERT INTO` for that.
```

</details>

---

## Question 4

```markdown
Which ksqlDB object type supports pull queries?
```

**Options**

```markdown
- A. STREAM
- B. TABLE
- C. TOPIC
- D. VIEW
```

<details><summary>Response:</summary>

**Answer:** B

**Explanation:**

```markdown
- A. Streams don’t maintain latest state.
- B. ✅ Correct – tables support stateful lookups.
- C. Kafka topic isn't a ksqlDB queryable object.
- D. VIEW is not a native ksqlDB entity.
```

</details>

---

## Question 5

```markdown
Consider the following KSQL statement to create a stream from a Kafka topic. Identify the issue in the code and explain how to fix it.

CREATE STREAM orders (
  order_id INT KEY,
  order_amount DOUBLE,
  order_time BIGINT
) WITH (
  KAFKA_TOPIC='orders-topic',
  VALUE_FORMAT='JSON'
);
```

**Options**
```markdown
- A. The VALUE_FORMAT should be AVRO.
- B. The KAFKA_TOPIC property should be TOPIC_NAME.
- C. The order_id field should be of type VARCHAR.
- D. The CREATE STREAM statement is correct; no changes are needed.
```

<details><summary>Response:</summary>

**Answer:** C

**Explanation:**

```markdown
The issue in the provided CREATE STREAM statement is that the order_id field is incorrectly defined as INT. In KSQL, Kafka keys and values are typically represented as strings for JSON format. The order_id field should be of type VARCHAR.
```

</details>

---

## Question 6

```markdown
Which keyword is used to create a persistent query in KSQL?
```

**Options**

```markdown
- A. PERSIST
- B. CREATE STREAM AS
- C. CREATE PERSISTENT QUERY
- D. SAVE
```

<details><summary>Response:</summary> 

**Answer:** B

**Explanation:**

```markdown
The `CREATE STREAM AS` keyword is used to create a persistent query in KSQL. This query continuously processes data and stores the results in a new stream.

- A, C, and D are incorrect because they are not valid keywords for creating a persistent query in KSQL.
```

</details>

---

## Question 7

```markdown
Which statement is true about KSQL streams?
```

**Options**

```markdown
- A. They store historical data indefinitely
- B. They are append-only collections of immutable records
- C. They can be directly queried for the current state
- D. They do not support windowed aggregations
```

<details><summary>Response:</summary> 

**Answer:** B

**Explanation:**

```markdown
KSQL streams are append-only collections of immutable records that represent the continuous flow of data.

- A, C, and D are incorrect because streams do not store data indefinitely, they represent immutable records, and they do support windowed aggregations.
```

</details>

---

## Question 8

```markdown
Which of the following SELECT queries is invalid in ksqlDB?
```

**Options**

```markdown
- A. `SELECT * FROM user_clicks;`
- B. `SELECT * FROM user_profiles EMIT CHANGES;`
- C. `SELECT * FROM user_profiles WHERE user_id = 'abc';`
- D. `SELECT COUNT(*) FROM user_clicks;`
```

<details><summary>Response:</summary>

**Answer:** A

**Explanation:**

```markdown
- A. ✅ Missing EMIT CHANGES or pull clause.
- B. Valid push query on a table.
- C. Valid pull query on table.
- D. Valid if used with GROUP BY or EMIT CHANGES.
```

</details>

---

## Question 9

```markdown
Why must the schema defined in `CREATE STREAM` match the Kafka topic structure?
```

**Options**

```markdown
- A. To support stateful transformations
- B. Because mismatched schemas cause deserialization errors
- C. To allow use of Avro format only
- D. So ksqlDB can perform aggregations
```

<details><summary>Response:</summary>

**Answer:** B

**Explanation:**

```markdown
- A. Statefulness is unrelated to schema validation.
- B. ✅ Schema mismatch breaks parsing.
- C. Applies to all formats, not just Avro.
- D. Aggregation doesn’t depend on schema match.
```

</details>

---

## Question 10

```markdown
Which query pattern returns the latest value of a record by key?
```

**Options**

```markdown
- A. `SELECT * FROM my_stream EMIT CHANGES;`
- B. `SELECT * FROM my_table EMIT CHANGES;`
- C. `SELECT * FROM my_table WHERE key = 'k1';`
- D. `SELECT * FROM my_stream WHERE key = 'k1';`
```

<details><summary>Response:</summary>

**Answer:** C

**Explanation:**

```markdown
- A. Continuous stream output, not latest value.
- B. Table + EMIT = push query.
- C. ✅ Pull query for single value by key.
- D. Streams can’t be queried this way.
```

</details>

---

## Question 11

```markdown
Which data type in ksqlDB is used for timestamp-like data in a stream?
```

**Options**

```markdown
- A. TIME
- B. TIMESTAMP
- C. BIGINT
- D. STRING
```

<details><summary>Response:</summary>

**Answer:** C

**Explanation:**

```markdown
- A. Not a recognized type in ksqlDB.
- B. Exists, but internal timestamping uses BIGINT.
- C. ✅ BIGINT stores epoch milliseconds.
- D. STRING is not time-efficient.
```

</details>

---

## Question 12

```markdown
What is the role of the `KEY` keyword in KSQL table creation?
```

**Options**

```markdown
- A. To define the primary key of the table
- B. To specify the partitioning key of the table
- C. To assign a unique identifier to each record
- D. To create an index on the table
```

<details><summary>Response:</summary> 

**Answer:** A

**Explanation:**

```markdown
The `KEY` keyword in KSQL table creation is used to specify the primary key of the table, which is also used for partitioning.

- B, C, and D are incorrect because they do not accurately describe the role of the `KEY` keyword in KSQL.
```

</details>

---

## Question 13

```markdown
Why might you prefer AVRO over JSON for data serialization in ksqlDB?
```

**Options**

```markdown
- A. AVRO is human-readable
- B. AVRO is the only supported format
- C. AVRO supports strong schema validation and evolution
- D. JSON lacks support for nested structures
```

<details><summary>Response:</summary>

**Answer:** C

**Explanation:**

```markdown
- A. JSON is more readable.
- B. ksqlDB supports JSON, AVRO, PROTOBUF.
- C. ✅ AVRO supports schema enforcement and versioning.
- D. JSON supports nesting too.
```

</details>

---

## Question 14

```markdown
How can you convert a stream into a table in KSQL?
```

**Options**

```markdown
- A. CREATE TABLE table_name AS SELECT * FROM stream_name;
- B. INSERT INTO table_name SELECT * FROM stream_name;
- C. CREATE TABLE table_name FROM stream_name;
- D. CONVERT STREAM stream_name TO TABLE table_name;
```

<details><summary>Response:</summary>

**Answer:** A

**Explanation:**

```markdown
The correct syntax to convert a stream into a table in KSQL is:

- A. `CREATE TABLE table_name AS SELECT * FROM stream_name;` — valid syntax for conversion.
- B. Incorrect, not valid syntax for this operation.
- C. Incorrect, invalid syntax.
- D. Incorrect, no such command in KSQL.
```

</details>

---

## Question 15

```markdown
What is the purpose of the `WITH` clause in `CREATE STREAM` or `CREATE TABLE`?
```

**Options**

```markdown
- A. Define the SELECT query logic
- B. Specify the serialization format and Kafka topic
- C. Describe the primary key columns
- D. Assign a schema ID for registry lookup
```

<details><summary>Response:</summary>

**Answer:** B

**Explanation:**

```markdown
- A. SELECT logic is separate from CREATE
- B. ✅ WITH clause defines KAFKA_TOPIC, VALUE_FORMAT, etc.
- C. PRIMARY KEY is defined in column list
- D. Schema ID is internal to Avro/Registry
```

</details>

---

## Question 16

```markdown
What happens when you run a CREATE STREAM statement without an AS SELECT clause in KSQL?
```

**Options**

```markdown
- A. It creates a new stream and writes metadata to the KSQL command topic.
- B. It creates a new stream and starts writing data to it from the KSQL application.
- C. It fails because CREATE STREAM must always include an AS SELECT clause.
- D. It creates a new empty stream but doesn't write anything to Kafka.
```

<details><summary>Response:</summary>

**Answer:** A

**Explanation:**

```markdown
CREATE STREAM without AS SELECT registers a stream on an existing topic; metadata is stored in the command topic.

- A. Correct – metadata is written.
- B. Incorrect – no data is written automatically.
- C. Incorrect – AS SELECT is optional.
- D. Incorrect – metadata is written, not the stream itself.
```

</details>

---

## Question 17

```markdown
What is the purpose of the PARTITIONS clause in a KSQL CREATE TABLE statement?
```

**Options**

```markdown
- A. To specify the number of partitions for the output Kafka topic
- B. To specify the partitioning key for the output Kafka topic
- C. To specify the number of partitions to read from the input Kafka topic
- D. To specify the partitioning key to read from the input Kafka topic
```

<details><summary>Response:</summary>

**Answer:** A

**Explanation:**

```markdown
The PARTITIONS clause defines how many partitions the resulting Kafka topic will have.

- A. Correct – controls output topic partitions.
- B. Incorrect – partitioning key is handled differently.
- C. Incorrect – input topic partitions are not configured here.
- D. Incorrect – key specification uses other syntax.
```

</details>

---

## Question 18

```markdown
What is a KSQL table?
```

**Options**

```markdown
- A. A mutable collection of key-value pairs
- B. An immutable, append-only collection of records
- C. A stateful, changelog-based table
- D. A temporary view of streaming data
```

<details><summary>Response:</summary>

**Answer:** C

**Explanation:**

```markdown
KSQL tables are stateful structures built from changelog topics.

- A. Too generic
- B. Describes a stream
- C. Correct – changelog-based table
- D. Incorrect – not temporary
```

</details>

---

## Question 19

```markdown
How can you create a stream in KSQL from an existing Kafka topic?
```

**Options**

```markdown
- A. CREATE STREAM stream_name FROM topic_name;
- B. CREATE STREAM stream_name (columns) WITH (kafka_topic='topic_name', value_format='format');
- C. CREATE STREAM stream_name WITH (kafka_topic='topic_name', value_format='format');
- D. CREATE STREAM stream_name AS SELECT * FROM topic_name;
```

<details><summary>Response:</summary>

**Answer:** B

**Explanation:**

```markdown
Correct syntax involves defining columns and specifying the topic and format.

- A. Incorrect – invalid syntax
- B. Correct
- C. Incorrect – missing column definition
- D. Incorrect – used for derived streams
```

</details>

---