## Question 1

```markdown
Which command would you use to check the health and status of the KRaft metadata quorum?
```

**Options**
```markdown
- A. kafka-metadata-shell.sh --bootstrap-server localhost:9092 --describe
- B. kafka-metadata-quorum.sh --bootstrap-server localhost:9092 --describe
- C. kafka-dump-log.sh --files metadata.log --describe
- D. kafka-cluster.sh --bootstrap-server localhost:9092 --quorum-status
```

<details><summary>Response:</summary>

**Answer:** B

**Explanation:**

```markdown
kafka-metadata-quorum.sh is specifically designed for quorum status monitoring in KRaft mode.

- A. kafka-metadata-shell.sh is for interactive exploration, not status reporting
- B. Correct - this command shows quorum health, leader info, and replication status
- C. kafka-dump-log.sh analyzes log files, not live quorum status
- D. kafka-cluster.sh doesn't have --quorum-status flag
```

</details>

## Question 2

```markdown
What does the --cluster-metadata-decoder flag do in kafka-dump-log.sh?
```

**Options**
```markdown
- A. Decodes consumer offset commits in the metadata log
- B. Formats output for cluster-wide metadata analysis
- C. Decodes KRaft metadata log entries into human-readable format
- D. Encodes metadata for backup purposes
```

<details><summary>Response:</summary>

**Answer:** C

**Explanation:**

```markdown
This flag is essential for reading KRaft metadata logs in readable format.

- A. Consumer offsets use --offsets-decoder, not cluster-metadata-decoder
- B. It decodes content, not just formats output
- C. Correct - transforms binary metadata log entries into readable text
- D. It decodes (reads), not encodes (writes) metadata
```

</details>

## Question 3

```markdown
Which command would you use to interactively explore the metadata stored in a KRaft snapshot file?
```

**Options**
```markdown
- A. kafka-metadata-quorum.sh --snapshot metadata.snapshot --explore
- B. kafka-metadata-shell.sh --snapshot metadata.checkpoint
- C. kafka-dump-log.sh --files metadata.log --interactive
- D. kafka-shell.sh --metadata-snapshot metadata.log
```

<details><summary>Response:</summary>

**Answer:** B

**Explanation:**

```markdown
kafka-metadata-shell.sh provides interactive exploration of metadata snapshots.

- A. kafka-metadata-quorum.sh doesn't have snapshot exploration capability
- B. Correct - this starts an interactive shell for metadata exploration
- C. kafka-dump-log.sh is for batch analysis, not interactive exploration
- D. kafka-shell.sh doesn't exist as a standard tool
```

</details>

## Question 4

```markdown
What is the purpose of the kafka-log-dirs.sh command?
```

**Options**
```markdown
- A. Creates new log directories for topic partitions
- B. Monitors disk usage and status of log directories across brokers
- C. Compacts log directories to save space
- D. Migrates log directories between brokers
```

<details><summary>Response:</summary>

**Answer:** B

**Explanation:**

```markdown
This command is crucial for disk space monitoring and log directory health checks.

- A. Log directory creation is automatic, not manual
- B. Correct - shows disk usage, partition sizes, and directory status
- C. Compaction is handled automatically by Kafka, not via this command
- D. Migration requires partition reassignment, not directory moving
```

</details>

## Question 5

```markdown
Which flag would you use with kafka-dump-log.sh to analyze consumer group offset commits?
```

**Options**
```markdown
- A. --consumer-offsets-decoder
- B. --offsets-decoder
- C. --group-metadata-decoder
- D. --commit-log-decoder
```

<details><summary>Response:</summary>

**Answer:** B

**Explanation:**

```markdown
The --offsets-decoder flag is specifically for consumer offset log analysis.

- A. Not a valid flag name
- B. Correct - decodes __consumer_offsets topic entries
- C. Group metadata is different from offset commits
- D. Not a standard flag in kafka-dump-log.sh
```

</details>

## Question 6

```markdown
What information does kafka-broker-api-versions.sh provide?
```

**Options**
```markdown
- A. The Kafka version installed on each broker
- B. API compatibility between brokers and clients
- C. The protocol versions supported by each broker
- D. The REST API endpoints available on each broker
```

<details><summary>Response:</summary>

**Answer:** C

**Explanation:**

```markdown
This command is essential for troubleshooting client-broker compatibility issues.

- A. Shows API versions, not software versions
- B. It shows supported versions, not specifically compatibility
- C. Correct - displays all Kafka protocol versions each broker supports
- D. Kafka uses binary protocol, not REST API
```

</details>

## Question 7

```markdown
Which command would you use to check for gaps in the metadata log?
```

**Options**
```markdown
- A. kafka-dump-log.sh --files metadata.log --check-gaps
- B. kafka-metadata-quorum.sh --validate-gaps
- C. kafka-dump-log.sh --files metadata.log --cluster-metadata-decoder --print-gaps
- D. kafka-log-dirs.sh --check-metadata-gaps
```

<details><summary>Response:</summary>

**Answer:** C

**Explanation:**

```markdown
Gap detection is crucial for identifying metadata corruption issues.

- A. --check-gaps is not a valid flag
- B. kafka-metadata-quorum.sh doesn't have gap detection
- C. Correct - this combination detects missing log segments
- D. kafka-log-dirs.sh is for disk space, not log content gaps
```

</details>

## Question 8

```markdown
What does the --deep-iteration flag do in kafka-dump-log.sh?
```

**Options**
```markdown
- A. Performs deeper validation of log integrity
- B. Iterates through corrupted log segments to recover data
- C. Provides more detailed output with additional message details
- D. Scans deeper into the log directory structure
```

<details><summary>Response:</summary>

**Answer:** C

**Explanation:**

```markdown
This flag enhances the detail level of log analysis output.

- A. Validation is done with --verify flag, not deep-iteration
- B. It doesn't handle corruption recovery, just detailed output
- C. Correct - shows additional message-level details and metadata
- D. Directory structure is handled by file path, not this flag
```

</details>

## Question 9

```markdown
Which command would you use to analyze transaction state information?
```

**Options**
```markdown
- A. kafka-dump-log.sh --files transaction.log --transaction-decoder
- B. kafka-dump-log.sh --files __transaction_state-0/*.log --transaction-log-decoder
- C. kafka-metadata-shell.sh --transaction-state
- D. kafka-transactions.sh --analyze-state
```

<details><summary>Response:</summary>

**Answer:** B

**Explanation:**

```markdown
Transaction log analysis requires the correct log file and decoder flag.

- A. --transaction-decoder is not the correct flag name
- B. Correct - uses the proper transaction log decoder for __transaction_state topics
- C. kafka-metadata-shell.sh doesn't handle transaction state analysis
- D. kafka-transactions.sh doesn't exist as a standard tool
```

</details>

## Question 10

```markdown
What is the purpose of the kafka-delegation-tokens.sh command?
```

**Options**
```markdown
- A. Manages SSL certificates for broker communication
- B. Handles OAuth2 token authentication
- C. Creates and manages delegation tokens for secure inter-broker communication
- D. Generates API keys for REST proxy access
```

<details><summary>Response:</summary>

**Answer:** C

**Explanation:**

```markdown
Delegation tokens provide secure authentication without distributing long-term credentials.

- A. SSL certificates are managed differently
- B. OAuth2 is a different authentication mechanism
- C. Correct - delegation tokens allow secure authentication between components
- D. API keys are for external API access, not internal broker communication
```

</details>

## Question 11

```markdown
Which command would help identify which broker is the current controller in a KRaft cluster?
```

**Options**
```markdown
- A. kafka-metadata-shell.sh --bootstrap-server localhost:9092 --command "cat /controller"
- B. kafka-metadata-quorum.sh --bootstrap-server localhost:9092 --describe --status
- C. kafka-configs.sh --bootstrap-server localhost:9092 --entity-type controller --describe
- D. kafka-cluster.sh --bootstrap-server localhost:9092 --controller-info
```

<details><summary>Response:</summary>

**Answer:** B

**Explanation:**

```markdown
Controller identification is a key function of the metadata quorum tool.

- A. The metadata path is /brokers, not /controller specifically
- B. Correct - shows current leader/controller ID in quorum status
- C. Controller is not an entity-type in kafka-configs.sh
- D. kafka-cluster.sh doesn't have --controller-info flag
```

</details>

## Question 12

```markdown
What does an "OFFLINE" error in kafka-log-dirs.sh output indicate?
```

**Options**
```markdown
- A. The broker is offline and cannot be reached
- B. The log directory is unmounted or inaccessible
- C. The topic partitions are offline due to replication issues
- D. The disk is full and cannot accept new writes
```

<details><summary>Response:</summary>

**Answer:** B

**Explanation:**

```markdown
Log directory status is critical for disk failure detection.

- A. Broker connectivity issues would prevent the command from running
- B. Correct - indicates disk mount issues or directory inaccessibility
- C. Partition availability is different from directory status
- D. Disk full would show different error messages or size constraints
```

</details>

--- 

## Question 13

```markdown
How will you find out all the partitions without a leader?
```

**Options**

```markdown
- A. kafka-topic.sh--broker-list localhost:9092 --describe--under-replicated-partitions
- B. kafka-topic.sh--broker-list localhost:2181 --describe--under-replicated-partitions
- C. kafka-topic.sh--zookeeper localhost:2181 --describe--unavailable-partitions
- D. kafka-topic.sh--zookeeper localhost:9092 --describe--unavailable-partitions
```

<details><summary>Response:</summary>

**Answer:** C

**Explanation:**

```markdown
To find unavailable partitions, the correct CLI is:

kafka-topic.sh --zookeeper localhost:2181 --describe --unavailable-partitions

Note: Starting from Kafka 2.2, --zookeeper is deprecated. The preferred way is:

kafka-topics.sh --bootstrap-server localhost:9092 --describe --unavailable-partitions

- A. Incorrect flag and argument for partition info
- B. Same issue as A, and incorrect port for Zookeeper
- C. ✅ Correct usage for unavailable partitions with Zookeeper
- D. Incorrect because port 9092 is for brokers, not Zookeeper
```

</details>

---

## Question 14

```markdown
The kafka-console-consumer CLI, when used with the default options:
```

**Options**

```markdown
- A. always use the same group id
- B. does not use the group id
- C. uses a random group id
```

<details><summary>Response:</summary>

**Answer:** C

**Explanation:**

```markdown
If you do not specify a `--group` option when using kafka-console-consumer, it generates a random group ID each time, meaning it won't commit offsets or maintain group state.

- A. Incorrect, unless explicitly defined
- B. Incorrect, a group is always assigned—even if randomly
- C. ✅ Correct — it assigns a random group ID
```

</details>

## Question 15

```markdown
How does the `kafka-console-consumer` behave when you specify the `--from-beginning` option?
```

**Options**

```markdown
- A. It starts consuming messages from the earliest available offset in the assigned partitions
- B. It starts consuming messages from the latest available offset in the assigned partitions
- C. It starts consuming messages from a specific offset that you provide
- D. It starts consuming messages from a random offset in the assigned partitions
```

<details><summary>Response:</summary>

**Answer:** A

**Explanation:**

```markdown
`--from-beginning` seeks to the earliest available offset.

- A. ✅ Correct – processes the full topic history.
- B. Default behavior without `--from-beginning`.
- C. `--from-beginning` doesn’t allow specific offsets.
- D. No randomness – it deterministically uses the start.
```

</details>

---

## Question 16

```markdown
What happens when you run multiple instances of the `kafka-console-consumer` with the same consumer group?
```

**Options**

```markdown
- A. The instances will consume messages independently, each receiving a copy of every message
- B. The instances will collaborate and distribute the partitions among themselves for parallel consumption
- C. The instances will compete for messages, and each message will be consumed by only one instance
- D. The instances will consume messages in a round-robin fashion, with each instance receiving a subset of messages
```

<details><summary>Response:</summary>

**Answer:** B

**Explanation:**

```markdown
Kafka distributes partitions to consumers in the same group.

- A. Not true – consumers don’t get duplicate messages.
- B. ✅ Partitions are split among group members.
- C. No competition—Kafka handles partition assignment.
- D. Assignment is by partition, not round-robin messages.
```

</details>

---

